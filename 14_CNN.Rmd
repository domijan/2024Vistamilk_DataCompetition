---
title: "CNN"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```




```{r load_libraries, warning = FALSE, message=FALSE}
library(tidyverse)
library(ggthemes)
library(gridExtra)


# if (tensorflow::tf$executing_eagerly())
#   tensorflow::tf$compat$v1$disable_eager_execution()
# 
# library(keras)
# # K <- keras::backend()

library(reticulate)
use_condaenv("tf-2.6") 
tensorflow <- import("tensorflow")
# Libraries ---------------------------------------------------------------
library(keras)
```

```{r read_data}

calcRMSE <- function(y, yhat){sqrt(mean((yhat - y)^2))}


specTrain <- readRDS("specTrain.rds")
specTest <- readRDS("specTest.rds")

# train <- read.csv("data/training.csv")
dim(specTrain)
# names(train)

sample <- specTrain$`sample number` |> unique()
set.seed(1951)
random_split <- replicate(1, sample(length(sample), 40))
```




## Split and scale data

```{r split_scale}

# lapply(dat.tr, function(x) sum(is.na(x))) |> str()

dat.tr <- specTrain |> 
  filter(`sample number` %in% sample[random_split[,1]])
dat.te <- specTrain |> 
  filter(`sample number` %in% sample[-random_split[,1]])


train_data <- dat.tr|> select(c(`412.71`: `3907.24`))
train_type <- dat.tr |> select(`lactose content` )
train_type <- as.matrix(train_type )

test_data <- dat.te|> select(c(`412.71`: `3907.24`))
test_type <- dat.te |> select(`lactose content` )
test_type <- as.matrix(test_type )

x_train <- array_reshape(as.matrix(train_data), c(nrow(train_data), ncol(train_data)), order = "F")

mn <- apply(x_train, 2, mean)
sd <- apply(x_train, 2, sd)

x_train <- sweep(x_train,2, mn, "-")
x_train <- sweep(x_train,2, sd, "/")

x_test <- array_reshape(as.matrix(test_data), c(nrow(test_data),ncol(test_data)), order = "F")

x_test <- sweep(x_test,2, mn, "-")
x_test <- sweep(x_test,2, sd, "/")


```

## CNN


```{r}


input_shape <- c(1813, 1)



cat('x_train_shape:', dim(x_train), '\n')
cat(nrow(x_train), 'train samples\n')
cat(nrow(x_test), 'test samples\n')


# Parameters --------------------------------------------------------------



batch_size <- 128
epochs <-  40
```


```{r eval  = FALSE}
# Model defn --------------------------------------------------------------

model <- keras_model_sequential() |>
  layer_conv_1d(filters = 16, kernel_size = c(3), padding = "same", activation = 'relu', kernel_initializer = "he_uniform",
                input_shape = input_shape) |> 
    layer_batch_normalization()|>
    layer_max_pooling_1d(pool_size = c(2)) |>
  layer_dropout(rate = 0.2) |>
  layer_conv_1d(filters = 16, kernel_size = c(3), padding = "same", activation = 'relu',kernel_initializer = "he_uniform") |>
    layer_batch_normalization()|>
  layer_max_pooling_1d(pool_size = c(2)) |>
  layer_dropout(rate = 0.2) |>
    layer_flatten() |> 
  layer_dense(units = 100, activation = 'relu') |> 
  layer_dropout(rate = 0.2) |> 
  layer_dense(units = 1)


summary(model)
```


```{r eval  = FALSE}

# Compile model ----------------------------------------------------

# model |> compile(
  # optimizer = optimizer_adam(learning_rate = 0.1),
  # loss = 'mean_absolute_error'
# )
model |> compile(
  loss = 'mean_absolute_error',
  optimizer = optimizer_sgd(learning_rate = 0.01, decay=1e-6, momentum = 0.9, nesterov = TRUE)
)

# Fit model to data
history <- model |> fit(
  x_train, train_type,
  batch_size = batch_size,
  epochs = 300,
  verbose = 1,
  validation_split = 0.2
)


```


```{r}

plot(history)

score <- model |> evaluate(
  x_test, test_type,
  verbose = 0
)

# Output metrics
cat('Test loss:', score[[1]], '\n')


pr <- predict(model, x_test)
calcRMSE(test_type, pr)
plot(test_type, pr)
```

